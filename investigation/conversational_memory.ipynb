{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_cohere import ChatCohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatCohere(model=\"command-r-plus-08-2024\",\n",
    "           max_tokens=256,\n",
    "           temperature=0.5\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagarwa2\\AppData\\Local\\Temp\\ipykernel_26520\\2126509654.py:11: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(llm=llm,\n"
     ]
    }
   ],
   "source": [
    "summary_prompt_template = \"\"\"Summarize the conversation and update with new lines.\n",
    "Current summary: {summary}\n",
    "New lines: {new_lines}\n",
    "Updated summary:\n",
    "\"\"\"\n",
    "summary_prompt = PromptTemplate(\n",
    "    template=summary_prompt_template,\n",
    "    input_variables=[\"summary\", \"new_lines\"]\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm,\n",
    "                                   prompt=summary_prompt,\n",
    "                                   memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationSummaryMemory(llm=ChatCohere(client=<cohere.client.Client object at 0x000002CA66AB68B0>, async_client=<cohere.client.AsyncClient object at 0x000002CA66AB6A00>, model='command-r-plus-08-2024', temperature=0.5, cohere_api_key=SecretStr('**********')), prompt=PromptTemplate(input_variables=['new_lines', 'summary'], input_types={}, partial_variables={}, template='Summarize the conversation and update with new lines.\\nCurrent summary: {summary}\\nNew lines: {new_lines}\\nUpdated summary:\\n'), chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='hi', additional_kwargs={}, response_metadata={}), AIMessage(content='whats up', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"How's the weather today?\", additional_kwargs={}, response_metadata={}), AIMessage(content='It is cold outside.', additional_kwargs={}, response_metadata={})]), buffer=\"Current summary: The user starts a friendly interaction, and the AI promptly greets them, expressing readiness to help. The user then asks about the weather conditions.\\n\\nNew lines:\\n\\nHuman: How's the weather today?\\nAI: It's a chilly one! The temperature is around 5째C (41째F), and there's a crisp breeze blowing. You might want to grab a warm jacket if you're heading outdoors.\\n\\nUpdated summary: The user inquires about the day's weather, and the AI provides a detailed response, describing the cold temperature and suggesting appropriate attire for the user's comfort.\", memory_key='chat_history')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': 'Current summary: The conversation begins with a friendly greeting from the human user.\\n\\nNew lines:\\nHuman: Hey there!\\nAI: Hello! How can I assist you today?\\n\\nUpdated summary: The user initiates a conversation with a greeting, and the AI responds with a welcoming message, offering assistance.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"How's the weather today?\"}, {\"output\": \"It is cold outside.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': \"Current summary: The user starts a friendly interaction, and the AI promptly greets them, expressing readiness to help. The user then asks about the weather conditions.\\n\\nNew lines:\\n\\nHuman: How's the weather today?\\nAI: It's a chilly one! The temperature is around 5째C (41째F), and there's a crisp breeze blowing. You might want to grab a warm jacket if you're heading outdoors.\\n\\nUpdated summary: The user inquires about the day's weather, and the AI provides a detailed response, describing the cold temperature and suggesting appropriate attire for the user's comfort.\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
